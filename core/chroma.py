import chromadb
from chromadb.utils.embedding_functions import DefaultEmbeddingFunction

chroma_client = chromadb.HttpClient(host='10.112.154.220', port=8001)
default_ef = DefaultEmbeddingFunction()
#chroma_client.delete_collection(name="my_collection")

# switch create_collection to get_or_create_collection to avoid creating a new collection every time 
collection = chroma_client.get_or_create_collection(name="my_collection", embedding_function =default_ef)

# switch add to upsert to avoid adding the same documents every time 
collection.upsert(
	#documents=[
	#	"Kafka Project\n\nThis repository contains a simple implementation for using [Apache Kafka](https://kafka.apache.org/) with [Producer](https://kafka.apache.org/documentation/#producer) and [Consumer](https://kafka.apache.org/documentation/#consumer) applications, demonstrating how to send and receive messages between different systems. The project aims to provide a quick start for integrating Kafka into your applications and understanding basic Kafka operations.\n\n## Table of Contents\n- [Prerequisites](#prerequisites)\n- [Installation](#installation)\n- [Configuration](#configuration)\n- [Usage](#usage)\n- [Running Kafka Locally](#running-kafka-locally)\n- [Example Code](#example-code)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Prerequisites\n\nBefore you begin, ensure you have the following tools installed on your machine:\n\n- Java 8+ (Kafka is written in Java)\n- Apache Kafka (Follow the official [Kafka installation guide](https://kafka.apache.org/quickstart))\n- Apache ZooKeeper (Kafka requires ZooKeeper for distributed coordination)\n- [Maven](https://maven.apache.org/) or [Gradle](https://gradle.org/) for building the project\n- Docker (optional, if using for local Kafka setup)\n\n## Installation\n\n### Clone the Repository\n\n```bash\ngit clone https://github.com/yourusername/kafka-project.git\ncd kafka-project\n```\n\n### Build the Project\n\nIf you are using Maven, run the following command to build the project:\n\n```bash\nmvn clean install\n```\n\nIf you prefer Gradle, use:\n\n```bash\ngradle build\n```\n\n### Dependencies\n\n- Apache Kafka Client (`org.apache.kafka:kafka-clients:2.8.0`)\n- SLF4J Logger (`org.slf4j:slf4j-api:1.7.32`)\n\n## Configuration\n\nMake sure Kafka and ZooKeeper are running before starting the producer and consumer. You can configure the properties in the `application.properties` file or pass them via command line arguments.\n\nExample configuration file `config/application.properties`:\n\n```properties\n# Kafka configuration\nkafka.bootstrap.servers=localhost:9092\nkafka.group.id=my-group\nkafka.topic=test-topic\n```\n\n## Usage\n\n### Producer\n\nTo start a Kafka producer that sends messages to a topic:\n\n```java\npublic class ProducerExample {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(\"bootstrap.servers\", \"localhost:9092\");\n        props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n        props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n        Producer<String, String> producer = new KafkaProducer<>(props);\n\n        ProducerRecord<String, String> record = new ProducerRecord<>(\"test-topic\", \"key\", \"Hello, Kafka!\");\n        try {\n            producer.send(record);\n            System.out.println(\"Message sent successfully\");\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            producer.close();\n        }\n    }\n}\n```\n\n### Consumer\n\nTo consume messages from Kafka:\n\n```java\npublic class ConsumerExample {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(\"bootstrap.servers\", \"localhost:9092\");\n        props.put(\"group.id\", \"my-group\");\n        props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\n        props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\n\n        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n        consumer.subscribe(Collections.singletonList(\"test-topic\"));\n\n        while (true) {\n            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));\n            for (ConsumerRecord<String, String> record : records) {\n                System.out.printf(\"Consumed record with key = %s, value = %s%n\", record.key(), record.value());\n            }\n        }\n    }\n}\n```\n\n### Running Kafka Locally (via Docker)\n\nTo quickly get Kafka up and running locally, you can use Docker. Here's a basic `docker-compose.yml` file to run both Kafka and ZooKeeper.\n\n```yaml\nversion: '2'\nservices:\n  zookeeper:\n    image: wurstmeister/zookeeper:3.4.6\n    ports:\n      - \"2181:2181\"\n  kafka:\n    image: wurstmeister/kafka:latest\n    environment:\n      KAFKA_ADVERTISED_LISTENER: INSIDE:9093\n      KAFKA_LISTENER_SECURITY_PROTOCOL: PLAINTEXT\n      KAFKA_LISTENER_NAME_INTERNAL: INSIDE\n      KAFKA_LISTENER_INTERNAL_PORT: 9093\n      KAFKA_LISTENER_PORT: 9092\n      KAFKA_LISTENER_NAME_EXTERNAL: EXTERNAL\n      KAFKA_LISTENER_EXTERNAL_PORT: 9092\n      KAFKA_LISTENER_PROTOCOL: INSIDE\n      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\n    ports:\n      - \"9092:9092\"\n    depends_on:\n      - zookeeper\n```\n\nRun the containers:\n\n```bash\ndocker-compose up\n```\n\nThis will start both ZooKeeper and Kafka on your local machine, accessible at `localhost:9092`.\n\n## Example Code\n\nThe example code provided in the `src` directory demonstrates how to interact with Kafka using both the producer and consumer patterns. Modify the configurations in `application.properties` to match your Kafka setup.\n\n## Contributing\n\nWe welcome contributions to improve this project. Here’s how you can contribute:\n\n1. Fork this repository.\n2. Create a new branch (`git checkout -b feature-branch`).\n3. Make your changes.\n4. Commit your changes (`git commit -am 'Add new feature'`).\n5. Push to the branch (`git push origin feature-branch`).\n6. Open a pull request.\n\n## License\n\nThis project is licensed under the MIT License – see the [LICENSE](LICENSE) file for details.",
	#	"Kafka Project\n\nThis repository demonstrates basic usage of Apache Kafka for building producer and consumer applications. It provides an easy-to-understand implementation to help developers get started with Kafka messaging patterns.\n\n## Table of Contents\n- [Prerequisites](#prerequisites)\n- [Installation](#installation)\n- [Usage](#usage)\n- [Configuration](#configuration)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Prerequisites\n\nEnsure you have the following installed:\n- Java 8+\n- Apache Kafka\n- Apache ZooKeeper\n- Maven or Gradle for building the project\n\n## Installation\n\nClone the repository and build it using Maven or Gradle:\n\n```bash\n# Clone the repo\ngit clone https://github.com/yourusername/kafka-project.git\ncd kafka-project\n# Build with Maven\nmvn clean install\n```\n\nAlternatively, build with Gradle:\n\n```bash\ngradle build\n```\n\n## Usage\n\n### Producer Example\n\nThe Kafka producer sends messages to a Kafka topic. The example below demonstrates how to configure and send a simple message to a topic.\n\n```java\npublic class ProducerExample {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(\"bootstrap.servers\", \"localhost:9092\");\n        props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n        props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n        Producer<String, String> producer = new KafkaProducer<>(props);\n        producer.send(new ProducerRecord<>(\"test-topic\", \"key\", \"Hello Kafka!\"));\n        producer.close();\n    }\n}\n```\n\n### Consumer Example\n\nThe Kafka consumer listens for messages from a Kafka topic. Here’s an example of how to consume messages:\n\n```java\npublic class ConsumerExample {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(\"bootstrap.servers\", \"localhost:9092\");\n        props.put(\"group.id\", \"my-group\");\n        props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\n        props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\n\n        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n        consumer.subscribe(Collections.singletonList(\"test-topic\"));\n\n        while (true) {\n            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));\n            for (ConsumerRecord<String, String> record : records) {\n                System.out.println(record.value());\n            }\n        }\n    }\n}\n```\n\n## Configuration\n\nEnsure you have Kafka and ZooKeeper running locally or configure them remotely. Modify `application.properties` for Kafka configuration:\n\n```properties\nkafka.bootstrap.servers=localhost:9092\nkafka.group.id=my-group\nkafka.topic=test-topic\n```\n\n## Contributing\n\nFeel free to contribute! Fork the repository, make your changes, and submit a pull request. Ensure that all new code is properly tested.\n\n## License\n\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more information."
	#],
	embeddings=default_ef([
		"Kafka Project\n\nThis repository contains a simple implementation for using [Apache Kafka](https://kafka.apache.org/) with [Producer](https://kafka.apache.org/documentation/#producer) and [Consumer](https://kafka.apache.org/documentation/#consumer) applications, demonstrating how to send and receive messages between different systems. The project aims to provide a quick start for integrating Kafka into your applications and understanding basic Kafka operations.\n\n## Table of Contents\n- [Prerequisites](#prerequisites)\n- [Installation](#installation)\n- [Configuration](#configuration)\n- [Usage](#usage)\n- [Running Kafka Locally](#running-kafka-locally)\n- [Example Code](#example-code)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Prerequisites\n\nBefore you begin, ensure you have the following tools installed on your machine:\n\n- Java 8+ (Kafka is written in Java)\n- Apache Kafka (Follow the official [Kafka installation guide](https://kafka.apache.org/quickstart))\n- Apache ZooKeeper (Kafka requires ZooKeeper for distributed coordination)\n- [Maven](https://maven.apache.org/) or [Gradle](https://gradle.org/) for building the project\n- Docker (optional, if using for local Kafka setup)\n\n## Installation\n\n### Clone the Repository\n\n```bash\ngit clone https://github.com/yourusername/kafka-project.git\ncd kafka-project\n```\n\n### Build the Project\n\nIf you are using Maven, run the following command to build the project:\n\n```bash\nmvn clean install\n```\n\nIf you prefer Gradle, use:\n\n```bash\ngradle build\n```\n\n### Dependencies\n\n- Apache Kafka Client (`org.apache.kafka:kafka-clients:2.8.0`)\n- SLF4J Logger (`org.slf4j:slf4j-api:1.7.32`)\n\n## Configuration\n\nMake sure Kafka and ZooKeeper are running before starting the producer and consumer. You can configure the properties in the `application.properties` file or pass them via command line arguments.\n\nExample configuration file `config/application.properties`:\n\n```properties\n# Kafka configuration\nkafka.bootstrap.servers=localhost:9092\nkafka.group.id=my-group\nkafka.topic=test-topic\n```\n\n## Usage\n\n### Producer\n\nTo start a Kafka producer that sends messages to a topic:\n\n```java\npublic class ProducerExample {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(\"bootstrap.servers\", \"localhost:9092\");\n        props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n        props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n        Producer<String, String> producer = new KafkaProducer<>(props);\n\n        ProducerRecord<String, String> record = new ProducerRecord<>(\"test-topic\", \"key\", \"Hello, Kafka!\");\n        try {\n            producer.send(record);\n            System.out.println(\"Message sent successfully\");\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            producer.close();\n        }\n    }\n}\n```\n\n### Consumer\n\nTo consume messages from Kafka:\n\n```java\npublic class ConsumerExample {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(\"bootstrap.servers\", \"localhost:9092\");\n        props.put(\"group.id\", \"my-group\");\n        props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\n        props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\n\n        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n        consumer.subscribe(Collections.singletonList(\"test-topic\"));\n\n        while (true) {\n            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));\n            for (ConsumerRecord<String, String> record : records) {\n                System.out.printf(\"Consumed record with key = %s, value = %s%n\", record.key(), record.value());\n            }\n        }\n    }\n}\n```\n\n### Running Kafka Locally (via Docker)\n\nTo quickly get Kafka up and running locally, you can use Docker. Here's a basic `docker-compose.yml` file to run both Kafka and ZooKeeper.\n\n```yaml\nversion: '2'\nservices:\n  zookeeper:\n    image: wurstmeister/zookeeper:3.4.6\n    ports:\n      - \"2181:2181\"\n  kafka:\n    image: wurstmeister/kafka:latest\n    environment:\n      KAFKA_ADVERTISED_LISTENER: INSIDE:9093\n      KAFKA_LISTENER_SECURITY_PROTOCOL: PLAINTEXT\n      KAFKA_LISTENER_NAME_INTERNAL: INSIDE\n      KAFKA_LISTENER_INTERNAL_PORT: 9093\n      KAFKA_LISTENER_PORT: 9092\n      KAFKA_LISTENER_NAME_EXTERNAL: EXTERNAL\n      KAFKA_LISTENER_EXTERNAL_PORT: 9092\n      KAFKA_LISTENER_PROTOCOL: INSIDE\n      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\n    ports:\n      - \"9092:9092\"\n    depends_on:\n      - zookeeper\n```\n\nRun the containers:\n\n```bash\ndocker-compose up\n```\n\nThis will start both ZooKeeper and Kafka on your local machine, accessible at `localhost:9092`.\n\n## Example Code\n\nThe example code provided in the `src` directory demonstrates how to interact with Kafka using both the producer and consumer patterns. Modify the configurations in `application.properties` to match your Kafka setup.\n\n## Contributing\n\nWe welcome contributions to improve this project. Here’s how you can contribute:\n\n1. Fork this repository.\n2. Create a new branch (`git checkout -b feature-branch`).\n3. Make your changes.\n4. Commit your changes (`git commit -am 'Add new feature'`).\n5. Push to the branch (`git push origin feature-branch`).\n6. Open a pull request.\n\n## License\n\nThis project is licensed under the MIT License – see the [LICENSE](LICENSE) file for details.",
		"Kafka Project\n\nThis repository demonstrates basic usage of Apache Kafka for building producer and consumer applications. It provides an easy-to-understand implementation to help developers get started with Kafka messaging patterns.\n\n## Table of Contents\n- [Prerequisites](#prerequisites)\n- [Installation](#installation)\n- [Usage](#usage)\n- [Configuration](#configuration)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Prerequisites\n\nEnsure you have the following installed:\n- Java 8+\n- Apache Kafka\n- Apache ZooKeeper\n- Maven or Gradle for building the project\n\n## Installation\n\nClone the repository and build it using Maven or Gradle:\n\n```bash\n# Clone the repo\ngit clone https://github.com/yourusername/kafka-project.git\ncd kafka-project\n# Build with Maven\nmvn clean install\n```\n\nAlternatively, build with Gradle:\n\n```bash\ngradle build\n```\n\n## Usage\n\n### Producer Example\n\nThe Kafka producer sends messages to a Kafka topic. The example below demonstrates how to configure and send a simple message to a topic.\n\n```java\npublic class ProducerExample {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(\"bootstrap.servers\", \"localhost:9092\");\n        props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n        props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n        Producer<String, String> producer = new KafkaProducer<>(props);\n        producer.send(new ProducerRecord<>(\"test-topic\", \"key\", \"Hello Kafka!\"));\n        producer.close();\n    }\n}\n```\n\n### Consumer Example\n\nThe Kafka consumer listens for messages from a Kafka topic. Here’s an example of how to consume messages:\n\n```java\npublic class ConsumerExample {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(\"bootstrap.servers\", \"localhost:9092\");\n        props.put(\"group.id\", \"my-group\");\n        props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\n        props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\n\n        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n        consumer.subscribe(Collections.singletonList(\"test-topic\"));\n\n        while (true) {\n            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));\n            for (ConsumerRecord<String, String> record : records) {\n                System.out.println(record.value());\n            }\n        }\n    }\n}\n```\n\n## Configuration\n\nEnsure you have Kafka and ZooKeeper running locally or configure them remotely. Modify `application.properties` for Kafka configuration:\n\n```properties\nkafka.bootstrap.servers=localhost:9092\nkafka.group.id=my-group\nkafka.topic=test-topic\n```\n\n## Contributing\n\nFeel free to contribute! Fork the repository, make your changes, and submit a pull request. Ensure that all new code is properly tested.\n\n## License\n\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more information."
	]),
	ids=["id1", "id2"]
)

results = collection.query(
	query_embeddings=default_ef("what is kafka?"),
	#query_texts=["Parallel Datasets avro"], # Chroma will embed this for you
	n_results=1 # how many results tor eturn
)

print(default_ef(results['documents'][0]))
print(results)